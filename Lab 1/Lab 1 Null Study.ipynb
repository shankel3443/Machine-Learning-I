{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericl\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (7,19,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75749"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"NY_Listings.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75,749 rows leaves us plenty of wiggle room. Down below, you'll find a summary of null values and my tentative plan for dealing with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Listing ID                         0\n",
       "Name                              31\n",
       "Host ID                            0\n",
       "Host Name                        232\n",
       "Host Response Rate             45118\n",
       "Host Is Superhost                  0\n",
       "Host total listings count        232\n",
       "Street                         31439\n",
       "City                               0\n",
       "Neighbourhood cleansed             0\n",
       "State                              0\n",
       "Country                            0\n",
       "latitude                           0\n",
       "longitude                          0\n",
       "Property type                      0\n",
       "Room type                          0\n",
       "Accommodates                   31439\n",
       "Bathrooms                      31581\n",
       "Bedrooms                       31439\n",
       "Amenities                      31721\n",
       "Price                              0\n",
       "Minimum nights                     0\n",
       "Maximum nights                 31439\n",
       "Availability 365                   0\n",
       "Calendar last scraped          31439\n",
       "Number of reviews                  0\n",
       "Last Review Date               16683\n",
       "Review Scores Rating               0\n",
       "Review Scores Accuracy             0\n",
       "Review Scores Cleanliness          0\n",
       "Review Scores Checkin              0\n",
       "Review Scores Communication        0\n",
       "Review Scores Location             0\n",
       "Review Scores Value                0\n",
       "Reviews per month                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unwanted columns\n",
    "\n",
    "As you can see above, there's a concerning amount of null values. Some of these columns don't really matter. These include Name, Host Name, Calendar last scraped, and Last Review Date. Some of these columns could provide some information, but overall, I'm okay to exclude them from any work we do - especially since the text columns won't give us anything unless we do some language processing.\n",
    "\n",
    "So for now, I'm just going to remove those columns from the dataset and see how things look after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Listing ID                         0\n",
       "Host ID                            0\n",
       "Host Response Rate             45118\n",
       "Host Is Superhost                  0\n",
       "Host total listings count        232\n",
       "Street                         31439\n",
       "City                               0\n",
       "Neighbourhood cleansed             0\n",
       "State                              0\n",
       "Country                            0\n",
       "latitude                           0\n",
       "longitude                          0\n",
       "Property type                      0\n",
       "Room type                          0\n",
       "Accommodates                   31439\n",
       "Bathrooms                      31581\n",
       "Bedrooms                       31439\n",
       "Amenities                      31721\n",
       "Price                              0\n",
       "Minimum nights                     0\n",
       "Maximum nights                 31439\n",
       "Availability 365                   0\n",
       "Number of reviews                  0\n",
       "Review Scores Rating               0\n",
       "Review Scores Accuracy             0\n",
       "Review Scores Cleanliness          0\n",
       "Review Scores Checkin              0\n",
       "Review Scores Communication        0\n",
       "Review Scores Location             0\n",
       "Review Scores Value                0\n",
       "Reviews per month                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnsToRemove = [\"Name\", \"Host Name\", \"Calendar last scraped\", \"Last Review Date\"]\n",
    "\n",
    "df2 = df.drop(columns = columnsToRemove, axis=1)\n",
    "\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing rows with multiple columns missing\n",
    "\n",
    "Here, we've narrowed down the nulls a good amount. Now, lets try removing the rows where Street is null. I have a suspicion that all the rows with 31,439 nulls are the same. We could try to impute these values, but I fear that columns like Accommodates and Bedrooms are too important to guess on. And this would still leave us with 44,310 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Listing ID                         0\n",
       "Host ID                            0\n",
       "Host Response Rate             13679\n",
       "Host Is Superhost                  0\n",
       "Host total listings count        232\n",
       "Street                             0\n",
       "City                               0\n",
       "Neighbourhood cleansed             0\n",
       "State                              0\n",
       "Country                            0\n",
       "latitude                           0\n",
       "longitude                          0\n",
       "Property type                      0\n",
       "Room type                          0\n",
       "Accommodates                       0\n",
       "Bathrooms                        142\n",
       "Bedrooms                           0\n",
       "Amenities                        282\n",
       "Price                              0\n",
       "Minimum nights                     0\n",
       "Maximum nights                     0\n",
       "Availability 365                   0\n",
       "Number of reviews                  0\n",
       "Review Scores Rating               0\n",
       "Review Scores Accuracy             0\n",
       "Review Scores Cleanliness          0\n",
       "Review Scores Checkin              0\n",
       "Review Scores Communication        0\n",
       "Review Scores Location             0\n",
       "Review Scores Value                0\n",
       "Reviews per month                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2[df2['Street'].notnull()]\n",
    "\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44310"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last four columns\n",
    "Now that we're down to just four columns to look at, I'll take them one-by-one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bathrooms\n",
    "\n",
    "For Bathrooms, these 142 columns only represent .3% of the dataset. I think if we partition out by room type and property type, we can imput the means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Bathrooms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property type</th>\n",
       "      <th>Room type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Apartment</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <td>1.099828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private room</th>\n",
       "      <td>1.096143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shared room</th>\n",
       "      <td>1.082711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Bed &amp; Breakfast</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <td>1.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private room</th>\n",
       "      <td>1.182692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shared room</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">House</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <td>1.646916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private room</th>\n",
       "      <td>1.195214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shared room</th>\n",
       "      <td>1.692708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Bathrooms\n",
       "Property type   Room type                 \n",
       "Apartment       Entire home/apt   1.099828\n",
       "                Private room      1.096143\n",
       "                Shared room       1.082711\n",
       "Bed & Breakfast Entire home/apt   1.187500\n",
       "                Private room      1.182692\n",
       "                Shared room       1.000000\n",
       "House           Entire home/apt   1.646916\n",
       "                Private room      1.195214\n",
       "                Shared room       1.692708"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bathroomsIncluded = df3[df3['Bathrooms'].notnull()]\n",
    "bathroomsMissing = df3[df3['Bathrooms'].isna()]\n",
    "\n",
    "df4 = df3[[\"Property type\", \"Room type\", \"Bathrooms\"]]\n",
    "df4 = df4[(df4[\"Property type\"].isin(bathroomsMissing[\"Property type\"].unique()))]\n",
    "df4.groupby(by=[\"Property type\", \"Room type\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericl\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Listing ID                         0\n",
       "Host ID                            0\n",
       "Host Response Rate             13679\n",
       "Host Is Superhost                  0\n",
       "Host total listings count        232\n",
       "Street                             0\n",
       "City                               0\n",
       "Neighbourhood cleansed             0\n",
       "State                              0\n",
       "Country                            0\n",
       "latitude                           0\n",
       "longitude                          0\n",
       "Property type                      0\n",
       "Room type                          0\n",
       "Accommodates                       0\n",
       "Bathrooms                          0\n",
       "Bedrooms                           0\n",
       "Amenities                        282\n",
       "Price                              0\n",
       "Minimum nights                     0\n",
       "Maximum nights                     0\n",
       "Availability 365                   0\n",
       "Number of reviews                  0\n",
       "Review Scores Rating               0\n",
       "Review Scores Accuracy             0\n",
       "Review Scores Cleanliness          0\n",
       "Review Scores Checkin              0\n",
       "Review Scores Communication        0\n",
       "Review Scores Location             0\n",
       "Review Scores Value                0\n",
       "Reviews per month                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For these values, I feel comfortable assigning 1 to all groups except for House:Entire and House:Shared.\n",
    "# Those two groups will have 2 imputed.\n",
    "\n",
    "bathroomsOne = bathroomsMissing[(bathroomsMissing['Property type'].isin(['Apartment', 'Bed & Breakfast'])) | \n",
    "                                (bathroomsMissing['Property type'] == 'House') &\n",
    "                                (bathroomsMissing['Room type'] == 'Private room')]\n",
    "\n",
    "bathroomsTwo = bathroomsMissing[(bathroomsMissing['Property type'] == 'House') &\n",
    "                               (bathroomsMissing['Room type'] != 'Private room')]\n",
    "\n",
    "\n",
    "bathroomsOne.loc[:, \"Bathrooms\"] = 1\n",
    "bathroomsTwo.loc[:, \"Bathrooms\"] = 2\n",
    "\n",
    "df5 = pd.concat([bathroomsIncluded, bathroomsOne, bathroomsTwo], ignore_index=True, axis=0)\n",
    "\n",
    "df5.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amenities\n",
    "\n",
    "Now onto Amenities. Since this is a list of values, I really am not certain we'll be able to impute this unless we build some association model that picks up common sets of amenities. Personally, I don't really want to do that right now. I'm going to try and just remove then, considering this is only .05% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Listing ID                         0\n",
       "Host ID                            0\n",
       "Host Response Rate             13504\n",
       "Host Is Superhost                  0\n",
       "Host total listings count        227\n",
       "Street                             0\n",
       "City                               0\n",
       "Neighbourhood cleansed             0\n",
       "State                              0\n",
       "Country                            0\n",
       "latitude                           0\n",
       "longitude                          0\n",
       "Property type                      0\n",
       "Room type                          0\n",
       "Accommodates                       0\n",
       "Bathrooms                          0\n",
       "Bedrooms                           0\n",
       "Amenities                          0\n",
       "Price                              0\n",
       "Minimum nights                     0\n",
       "Maximum nights                     0\n",
       "Availability 365                   0\n",
       "Number of reviews                  0\n",
       "Review Scores Rating               0\n",
       "Review Scores Accuracy             0\n",
       "Review Scores Cleanliness          0\n",
       "Review Scores Checkin              0\n",
       "Review Scores Communication        0\n",
       "Review Scores Location             0\n",
       "Review Scores Value                0\n",
       "Reviews per month                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = df5[df5['Amenities'].notnull()]\n",
    "df6.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Host Response Rate\n",
    "\n",
    "I think this column is fairly important to predicting rating / price. Therefore, we can't just remove these rows. First, we can check for an overlap of hosts with included and missing values. For those that don't match - we may just need to impute the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host ID</th>\n",
       "      <th>Host Response Rate_x</th>\n",
       "      <th>Host Response Rate_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Host ID, Host Response Rate_x, Host Response Rate_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseIncluded = df6[df6['Host Response Rate'].notnull()]\n",
    "responseMissing = df6[df6['Host Response Rate'].isna()]\n",
    "\n",
    "responseIncluded_small = responseIncluded[[\"Host ID\", \"Host Response Rate\"]]\n",
    "responseMissing_small = responseMissing[[\"Host ID\", \"Host Response Rate\"]]\n",
    "\n",
    "responseMatches = pd.merge(left = responseIncluded_small, right = responseMissing_small, on=\"Host ID\", how=\"inner\")\n",
    "\n",
    "responseMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericl\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Listing ID                       0\n",
       "Host ID                          0\n",
       "Host Response Rate               0\n",
       "Host Is Superhost                0\n",
       "Host total listings count      227\n",
       "Street                           0\n",
       "City                             0\n",
       "Neighbourhood cleansed           0\n",
       "State                            0\n",
       "Country                          0\n",
       "latitude                         0\n",
       "longitude                        0\n",
       "Property type                    0\n",
       "Room type                        0\n",
       "Accommodates                     0\n",
       "Bathrooms                        0\n",
       "Bedrooms                         0\n",
       "Amenities                        0\n",
       "Price                            0\n",
       "Minimum nights                   0\n",
       "Maximum nights                   0\n",
       "Availability 365                 0\n",
       "Number of reviews                0\n",
       "Review Scores Rating             0\n",
       "Review Scores Accuracy           0\n",
       "Review Scores Cleanliness        0\n",
       "Review Scores Checkin            0\n",
       "Review Scores Communication      0\n",
       "Review Scores Location           0\n",
       "Review Scores Value              0\n",
       "Reviews per month                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseMissing.loc[:, \"Host Response Rate\"] = responseIncluded[\"Host Response Rate\"].median()\n",
    "\n",
    "df7 = pd.concat([responseIncluded, responseMissing], ignore_index=True, axis=0)\n",
    "\n",
    "df7.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Host total listings count\n",
    "\n",
    "We can again check for overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host ID</th>\n",
       "      <th>Host total listings count_x</th>\n",
       "      <th>Host total listings count_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Host ID, Host total listings count_x, Host total listings count_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listingsIncluded = df7[df7['Host total listings count'].notnull()]\n",
    "listingsMissing = df7[df7['Host total listings count'].isna()]\n",
    "\n",
    "listingsIncluded_small = listingsIncluded[[\"Host ID\", \"Host total listings count\"]]\n",
    "listingsMissing_small = listingsMissing[[\"Host ID\", \"Host total listings count\"]]\n",
    "\n",
    "listingsMatches = pd.merge(left = listingsIncluded_small, right = listingsMissing_small, on=\"Host ID\", how=\"inner\")\n",
    "\n",
    "listingsMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericl\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Listing ID                     0\n",
       "Host ID                        0\n",
       "Host Response Rate             0\n",
       "Host Is Superhost              0\n",
       "Host total listings count      0\n",
       "Street                         0\n",
       "City                           0\n",
       "Neighbourhood cleansed         0\n",
       "State                          0\n",
       "Country                        0\n",
       "latitude                       0\n",
       "longitude                      0\n",
       "Property type                  0\n",
       "Room type                      0\n",
       "Accommodates                   0\n",
       "Bathrooms                      0\n",
       "Bedrooms                       0\n",
       "Amenities                      0\n",
       "Price                          0\n",
       "Minimum nights                 0\n",
       "Maximum nights                 0\n",
       "Availability 365               0\n",
       "Number of reviews              0\n",
       "Review Scores Rating           0\n",
       "Review Scores Accuracy         0\n",
       "Review Scores Cleanliness      0\n",
       "Review Scores Checkin          0\n",
       "Review Scores Communication    0\n",
       "Review Scores Location         0\n",
       "Review Scores Value            0\n",
       "Reviews per month              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listingsMissing.loc[:, \"Host total listings count\"] = listingsIncluded[\"Host total listings count\"].median()\n",
    "\n",
    "df8 = pd.concat([listingsIncluded, listingsMissing], ignore_index=True, axis=0)\n",
    "\n",
    "df8.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44028"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.to_csv(#r\"C:\\Users\\ericl\\OneDrive\\Desktop\\SMU\\NY_Listings_Filtered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have no null values (can't be certain if there are values formatted incorrectly in the data though). I don't love some of these methods, so please let me know if y'all have any ideas! The row number is still about 50% more than the minimum, so I'm fairly happy with that.\n",
    "\n",
    "By the way, I did check the LA Listings. This set has about 20,000 less rows to begin with, but a similar amount of null values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
