{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2\n",
    "\n",
    "#### Alan Abadzic, John Girard, Eric Laigaie, Garrett Shankel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"NY_Listings_Validated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation Part 1\n",
    "\n",
    "*Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Grade Variable and Encode it\n",
    "def categorise(row):  \n",
    "    if row['Review Scores Rating'] > 89:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    return 'IDK'\n",
    "\n",
    "df['Grade'] = df.apply(lambda row: categorise(row), axis=1)\n",
    "\n",
    "df['Grade'].value_counts(normalize=True)\n",
    "\n",
    "# Filter to only useful columns\n",
    "data = df[['Host Response Rate', 'Host Is Superhost', 'Host total listings count', 'City', 'Room type',\n",
    "          'Accommodates', 'Bathrooms', 'Bedrooms', 'Price', 'Minimum nights', 'Maximum nights', 'Availability 365',\n",
    "          'Number of reviews', 'Reviews per month', 'Grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot Encode\n",
    "city_one_hot = pd.get_dummies(data['City'])\n",
    "room_one_hot = pd.get_dummies(data['Room type'])\n",
    "\n",
    "data = data.drop('City',axis = 1)\n",
    "data = data.drop('Room type',axis = 1)\n",
    "\n",
    "data = data.join(city_one_hot)\n",
    "data = data.join(room_one_hot)\n",
    "\n",
    "\n",
    "# Map boolean to integer\n",
    "data[\"Host Is Superhost\"] = data[\"Host Is Superhost\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "grade = data['Grade']\n",
    "to_scale = data.drop(\"Grade\", axis = 1)\n",
    "cols = to_scale.columns\n",
    "\n",
    "scaled = scaler.fit_transform(to_scale)\n",
    "\n",
    "data = pd.DataFrame(scaled, columns = cols)\n",
    "data['Grade'] = grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host Response Rate</th>\n",
       "      <th>Host Is Superhost</th>\n",
       "      <th>Host total listings count</th>\n",
       "      <th>Accommodates</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Minimum nights</th>\n",
       "      <th>Maximum nights</th>\n",
       "      <th>Availability 365</th>\n",
       "      <th>...</th>\n",
       "      <th>Reviews per month</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <th>Private room</th>\n",
       "      <th>Shared room</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043043</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>1.350418e-08</td>\n",
       "      <td>0.756164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028028</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>1.396984e-08</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062780</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.080080</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>1.396984e-08</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140140</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>5.234033e-07</td>\n",
       "      <td>0.980822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.234033e-07</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Host Response Rate  Host Is Superhost  Host total listings count  \\\n",
       "0                 1.0                0.0                   0.004086   \n",
       "1                 1.0                0.0                   0.001021   \n",
       "2                 1.0                0.0                   0.016343   \n",
       "3                 0.7                0.0                   0.001021   \n",
       "4                 1.0                0.0                   0.001021   \n",
       "\n",
       "   Accommodates  Bathrooms  Bedrooms     Price  Minimum nights  \\\n",
       "0      0.000000   0.064516  0.000000  0.043043        0.000801   \n",
       "1      0.000000   0.064516  0.000000  0.028028        0.000801   \n",
       "2      0.200000   0.193548  0.076923  0.080080        0.001601   \n",
       "3      0.200000   0.064516  0.000000  0.140140        0.000801   \n",
       "4      0.066667   0.064516  0.000000  0.060060        0.000000   \n",
       "\n",
       "   Maximum nights  Availability 365  ...  Reviews per month  Bronx  Brooklyn  \\\n",
       "0    1.350418e-08          0.756164  ...           0.072157    1.0       0.0   \n",
       "1    1.396984e-08          0.945205  ...           0.062780    1.0       0.0   \n",
       "2    1.396984e-08          0.972603  ...           0.156135    1.0       0.0   \n",
       "3    5.234033e-07          0.980822  ...           0.027313    1.0       0.0   \n",
       "4    5.234033e-07          0.986301  ...           0.150836    1.0       0.0   \n",
       "\n",
       "   Manhattan  Queens  Staten Island  Entire home/apt  Private room  \\\n",
       "0        0.0     0.0            0.0              0.0           1.0   \n",
       "1        0.0     0.0            0.0              0.0           1.0   \n",
       "2        0.0     0.0            0.0              0.0           1.0   \n",
       "3        0.0     0.0            0.0              1.0           0.0   \n",
       "4        0.0     0.0            0.0              0.0           1.0   \n",
       "\n",
       "   Shared room  Grade  \n",
       "0          0.0      1  \n",
       "1          0.0      0  \n",
       "2          0.0      1  \n",
       "3          0.0      0  \n",
       "4          0.0      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation Part 2\n",
    "\n",
    "*Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).*\n",
    "\n",
    "Below is table that describes each variable in the dataset. This includes our two predictor variables, Price and Grade. Additionally, all variables are of type float64, except for the int64 Grade.\n",
    "\n",
    "#### Variable Table\n",
    "| Variable | Description |\n",
    "| :-- | :-- |\n",
    "| Host Response Rate | The rate that hosts respond to potential customers. |\n",
    "| Host total listings count | The total number of airbnbs rentals the host owns. |\n",
    "| Accommodates | The number of people this rental can accommodate. |\n",
    "| Bathrooms | The number of bathrooms in this rental. |\n",
    "| Bedrooms | The number of bedrooms in this rental. |\n",
    "| Price | The base price for one night in this rental. |\n",
    "| Minimum nights | The lowest amount of nights this rental can be booked for. |\n",
    "| Maximum nights | The highest amount of nights this rental can be booked for. |\n",
    "| Availability 365 | The proportion of nights in a year that the rental is available. |\n",
    "| Reviews per month | The average number of reviews a rental receives in a month. |\n",
    "| Host Is Superhost | One-hot variable: A \"1\" indicates the rental is operated by a Superhost. |\n",
    "| Bronx | One-hot variable: A \"1\" indicates a Bronx-based rental. |\n",
    "| Brooklyn | One-hot variable: A \"1\" indicates a Brooklyn-based rental. |\n",
    "| Manhattan | One-hot variable: A \"1\" indicates a Manhattan-based rental. |\n",
    "| Queens | One-hot variable: A \"1\" indicates a Queens-based rental. |\n",
    "| Staten Island | One-hot variable: A \"1\" indicates a Staten Island-based rental. |\n",
    "| Entire home/apt | One-hot variable: A \"1\" indicates this rental is an entire home or apartment. |\n",
    "| Private room | One-hot variable: A \"1\" indicates this rental is a private room. |\n",
    "| Shared room | One-hot variable: A \"1\" indicates this rental is a shared room. |\n",
    "| Grade | One-hot variable: A \"1\" indicates this rental has a rating of .9 or more. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 1\n",
    "\n",
    "Choose and explain your evaluation metrics that you will use (i.e., accuracy,\n",
    "precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "#### Grade\n",
    "OPTION A:\n",
    "To measure a model's performance when predicting Grade classification, we will use an F1 score. We decided on this for a few reasons. First, there isn't a large difference in costs between a false negative and false positive. In the case of a false negative, customers will likely get a rental that exceeds their expectations. For a false positive, customers will have to deal with a worse rental than they might be expecting, but this rental could still has a passing review grade (70+). Additionally, the inbalanced class distribution (67% A's, 33% Non-A's) leads us to use F1 instead of plain accuracy due to F1's strength when dealing with unbalanced classes.\n",
    "\n",
    "OPTION B:\n",
    "To measure a model's performance when predicting Grade classification, we will use a sensitivity score. This is mainly due to the potential of a large negative costs for false positives. When a rental is given a false positive prediction, customers could be dealing with a rental that drastically fails their expectations.\n",
    "\n",
    "#### Price\n",
    "To measure a model's performance when predicting Price, we will use mean absolute percent error (MAPE). This option works well because it preserves the scale of the data (as opposed to squaring the difference), and provides a percentage value that is easier to interpret than a dollar value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 2\n",
    "\n",
    "Choose the method you will use for dividing your data into training and\n",
    "testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why\n",
    "your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "\n",
    "#### Grade\n",
    "On top of an 80% train, 20% test split, we will be using stratified 10-fold cross validation with grid search here. While non-stratified CV could also work, our imbalanced dataset (67% A's, 33% Non-A's) could yield folds of data that have very little Non-A's. Using stratification avoids this by holding these proportions constant across folds, leading to better training sets.\n",
    "\n",
    "#### Price\n",
    "On top of an 80% train, 20% test split, we will be using 10-fold cross validation with grid search here. We will not be using stratification because we're not dealing with inbalanced class labels that should be keep consistent. Since our response is continuous, we do not necessarily have to worry about certain outcomes not being selection for each fold.\n",
    "\n",
    "In both cases, grid search helps us determine the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 3\n",
    "\n",
    "Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "# Split data into train and test\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_y = train['Grade']\n",
    "train_x = train.drop('Grade', axis=1)\n",
    "test_y = train['Grade']\n",
    "test_x = train.drop('Grade', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Random Forest: 88.57%\n",
      "Time Elapsed: 17.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Make classifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Parameter Grid\n",
    "parameters = {'max_depth':(5, 10), 'min_samples_split':(2, 5, 10), 'splitter':('best', 'random')}\n",
    "\n",
    "# Make GridSearch - inputting a cv value toggles stratification on\n",
    "dt_cv = GridSearchCV(estimator = dt_clf, param_grid = parameters, cv = 10)\n",
    "\n",
    "# Fit\n",
    "start = time.time()\n",
    "dt_cv.fit(train_x,train_y)\n",
    "end = time.time()\n",
    "\n",
    "# Find best parameters and predict on them\n",
    "best_parameters = dt_cv.best_params_\n",
    "preds = dt_cv.predict(test_x)\n",
    "print(\"F1 Score for Random Forest: \" + str(round(f1_score(test_y, preds)*100,2)) + \"%\")\n",
    "print(\"Time Elapsed: \" + str(round(end-start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Logistic Regression: 78.35\n",
      "Time Elapsed: 200.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(max_iter = 100000)\n",
    "\n",
    "parameters = {'C':(1,10,100), 'solver':('lbfgs','saga')}\n",
    "lr_cv = GridSearchCV(estimator = lr_clf, param_grid = parameters, cv = 10)\n",
    "start = time.time()\n",
    "lr_cv.fit(train_x,train_y)\n",
    "end = time.time()\n",
    "\n",
    "best_parameters = lr_cv.best_params_\n",
    "preds = lr_cv.predict(test_x)\n",
    "print(\"F1 Score for Logistic Regression: \" + str(round(f1_score(test_y, preds)*100,2)) + \"%\")\n",
    "print(\"Time Elapsed: \" + str(round(end-start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade : KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for KNN: 85.26\n",
      "Time Elapsed: 357.3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors':(3,5,7), 'algorithm':('auto','kd_tree')}\n",
    "knn_cv = GridSearchCV(estimator = knn_clf, param_grid = parameters, cv = 10)\n",
    "start = time.time()\n",
    "knn_cv.fit(train_x,train_y)\n",
    "end = time.time()\n",
    "\n",
    "best_parameters = knn_cv.best_params_\n",
    "preds = knn_cv.predict(test_x)\n",
    "print(\"F1 Score for KNN: \" + str(round(f1_score(test_y, preds)*100,2)) + \"%\")\n",
    "print(\"Time Elapsed: \" + str(round(end-start,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Price column\n",
    "data['Price'] = df['Price']\n",
    "\n",
    "# Split data into train and test\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_y = train['Price']\n",
    "train_x = train.drop('Price', axis=1)\n",
    "test_y = train['Price']\n",
    "test_x = train.drop('Price', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price : Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percent Error for Linear Regression: 39.3%\n",
      "Time Elapsed: 1.38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.metrics import mean_absolute_error\n",
    "linr_clf = LinearRegression()\n",
    "\n",
    "parameters = {'fit_intercept':(True,False)}\n",
    "linr_cv = GridSearchCV(estimator = linr_clf, param_grid = parameters, cv = 10)\n",
    "start = time.time()\n",
    "linr_cv.fit(train_x,train_y)\n",
    "end = time.time()\n",
    "\n",
    "best_parameters = linr_cv.best_params_\n",
    "preds = linr_cv.predict(test_x)\n",
    "check_MAPE = pd.DataFrame()\n",
    "check_MAPE['real'], check_MAPE['preds'] = test_y, preds\n",
    "check_MAPE['diff'] = abs(check_MAPE['preds'] - check_MAPE['real']) / check_MAPE['real']\n",
    "check_MAPE = check_MAPE.replace(np.inf, np.nan)\n",
    "print(\"Mean Absolute Percent Error for Linear Regression: \" + str(round((check_MAPE['diff'].mean())*100,2)) + '%')\n",
    "print(\"Time Elapsed: \" + str(round(end-start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price : Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percent Error for Elastic Net Regression: 41.29%\n",
      "Time Elapsed: 13.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "el_clf = ElasticNet()\n",
    "\n",
    "parameters = {'l1_ratio':(.25,.5,.75),'alpha':(.1,1,10),'selection':('random','cyclic')}\n",
    "el_cv = GridSearchCV(estimator = el_clf, param_grid = parameters, cv = 10)\n",
    "start = time.time()\n",
    "el_cv.fit(train_x,train_y)\n",
    "end = time.time()\n",
    "\n",
    "best_parameters = el_cv.best_params_\n",
    "preds = el_cv.predict(test_x)\n",
    "check_MAPE = pd.DataFrame()\n",
    "check_MAPE['real'], check_MAPE['preds'] = test_y, preds\n",
    "check_MAPE['diff'] = abs(check_MAPE['preds'] - check_MAPE['real']) / check_MAPE['real']\n",
    "check_MAPE = check_MAPE.replace(np.inf, np.nan)\n",
    "print(\"Mean Absolute Percent Error for Elastic Net Regression: \" + str(round((check_MAPE['diff'].mean())*100,2)) + '%')\n",
    "print(\"Time Elapsed: \" + str(round(end-start,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price : Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-1e8f53b1914f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msvr_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvr_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msvr_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[0;32m    269\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_clf = SVR()\n",
    "\n",
    "parameters = {'kernel':('linear','rbf')}#,'gamma':('scale','auto')}\n",
    "svr_cv = GridSearchCV(estimator = svr_clf, param_grid = parameters, cv = 10)\n",
    "start = time.time()\n",
    "svr_cv.fit(train_x,train_y)\n",
    "end = time.time()\n",
    "\n",
    "best_parameters = svr_cv.best_params_\n",
    "preds = svr_cv.predict(test_x)\n",
    "check_MAPE = pd.DataFrame()\n",
    "check_MAPE['real'], check_MAPE['preds'] = test_y, preds\n",
    "check_MAPE['diff'] = abs(check_MAPE['preds'] - check_MAPE['real']) / check_MAPE['real']\n",
    "check_MAPE = check_MAPE.replace(np.inf, np.nan)\n",
    "print(\"Mean Absolute Percent Error for SVR: \" + str(round((1 - check_MAPE['diff'].mean())*100,2)) + '%')\n",
    "print(\"Time Elapsed: \" + str(round(end-start,2)))\n",
    "\n",
    "# THIS TAKES WAY TOO LONG - SHOULD SWITCH TO SOMETHING ELSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 4\n",
    "\n",
    "Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "SHOW MODEL ERROR/ACCURACY ON CHART WITH CONFIDENCE INTERVAL BARS? THAT WAY YOU COULD COMPARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 5\n",
    "\n",
    "Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "\n",
    "NOT SURE WHAT THEY'RE TALKING ABOUT WITH STATISTICAL TESTS TO COMPARE PERFORMANCE, I'LL HAVE TO GO LOOK THAT UP. BUT WE CAN SPEAK TO ADVANTAGES LIKE INTERPRETABILITY / TIME / ACCURACY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 6\n",
    "\n",
    "Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "\n",
    "WE DID SOMETHING VERY SIMILAR IN THE MINILAB. JUST NEED TO DO IT FOR THE BEST PRICE AND GRADE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? \n",
    "\n",
    "GRADE: POSSIBLY NOT THE MOST USEFUL MODEL WITHOUT EXTRA DATA. YOU COULD TRY AND CLASSIFY RENTALS WITH SMALL NUMBER OF REVIEWS (BASICALLY, TRYING TO JUMP THE GUN AND FIND GRADE STATUS BEFORE GETTING ENOUGH REVIEWS), BUT THAT COULD BE EXTRAPOLATION.\n",
    "\n",
    "PRICE: COULD BE USEFUL FOR AIRBNB TO FIND OVER/UNDERVALUED RENTALS TO CALIBRATE PRICING AND INCREASE BOOKINGS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptional Work\n",
    "\n",
    "You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
